<!DOCTYPE html>
<html lang="pt-BR">
  <head>
    <meta charset="UTF-8" />
    <title>Revis√£o - IA / ML</title>
    <style>
      body {
        font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI",
          sans-serif;
        margin: 0;
        padding: 0;
        background: #f3f4f6;
      }

      header {
        background: #111827;
        color: #f9fafb;
        padding: 16px 24px;
      }

      header h1 {
        margin: 0;
        font-size: 20px;
      }

      header p {
        margin: 4px 0 0;
        font-size: 13px;
        color: #d1d5db;
      }

      main {
        max-width: 900px;
        margin: 24px auto;
        background: #ffffff;
        padding: 24px;
        border-radius: 8px;
        box-shadow: 0 10px 25px rgba(0, 0, 0, 0.05);
      }

      .question {
        margin-bottom: 20px;
        padding-bottom: 16px;
        border-bottom: 1px solid #e5e7eb;
      }

      .question:last-child {
        border-bottom: none;
      }

      .question-title {
        font-weight: 600;
        margin-bottom: 8px;
      }

      .question-text {
        margin-bottom: 8px;
        line-height: 1.4;
      }

      .options {
        display: flex;
        flex-direction: column;
        gap: 4px;
        margin-left: 8px;
      }

      label {
        cursor: pointer;
        font-size: 14px;
      }

      .footer {
        margin-top: 24px;
        padding-top: 16px;
        border-top: 1px solid #e5e7eb;
        font-size: 13px;
        color: #6b7280;
      }

      .answers-hint {
        margin-bottom: 8px;
        font-style: italic;
      }

      .export-button {
        background: #2563eb;
        color: white;
        border: none;
        padding: 12px 24px;
        border-radius: 6px;
        font-size: 14px;
        font-weight: 600;
        cursor: pointer;
        margin-top: 16px;
        transition: background 0.2s;
      }

      .export-button:hover {
        background: #1d4ed8;
      }

      .export-button:active {
        background: #1e40af;
      }

      .answer-section {
        margin-top: 12px;
        border-top: 1px dashed #d1d5db;
        padding-top: 8px;
      }

      .show-answer-btn {
        background: #10b981;
        color: white;
        border: none;
        padding: 6px 12px;
        border-radius: 4px;
        font-size: 12px;
        font-weight: 600;
        cursor: pointer;
        transition: background 0.2s;
      }

      .show-answer-btn:hover {
        background: #059669;
      }

      .answer-content {
        display: none;
        margin-top: 8px;
        padding: 12px;
        background: #f0fdf4;
        border-left: 3px solid #10b981;
        border-radius: 4px;
      }

      .answer-content.visible {
        display: block;
      }

      .correct-answer {
        font-weight: 600;
        color: #059669;
        margin-bottom: 8px;
      }

      .explanation {
        font-size: 13px;
        color: #374151;
        line-height: 1.5;
      }
    </style>
  </head>
  <body>
    <header>
      <h1>Revis√£o ‚Äì Intelig√™ncia Artificial / Aprendizado de M√°quina</h1>
      <p>Marque suas respostas para estudo e revis√£o.</p>
    </header>

    <main>
      <form>
        <!-- 1 -->
        <div class="question">
          <div class="question-title">1)</div>
          <div class="question-text">
            Em rela√ß√£o aos algoritmos de busca informada, considere as
            afirmativas:<br />
            I. O algoritmo A* √© √≥timo e completo quando utiliza uma heur√≠stica
            admiss√≠vel.<br />
            II. A busca gulosa (greedy) sempre encontra a solu√ß√£o √≥tima por
            expandir menos n√≥s que o A*.<br />
            III. Uma heur√≠stica consistente (mon√≥tona) √© sempre admiss√≠vel, mas
            uma heur√≠stica admiss√≠vel n√£o √© necessariamente consistente.<br />
            Assinale a alternativa correta:
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q1" value="A" /> A) Apenas I √©
              verdadeira</label
            >
            <label
              ><input type="radio" name="q1" value="B" /> B) Apenas I e III s√£o
              verdadeiras</label
            >
            <label
              ><input type="radio" name="q1" value="C" /> C) Apenas II e III s√£o
              verdadeiras</label
            >
            <label
              ><input type="radio" name="q1" value="D" /> D) Todas s√£o
              verdadeiras</label
            >
            <label
              ><input type="radio" name="q1" value="E" /> E) Apenas I e II s√£o
              verdadeiras</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-1"
              onclick="toggleAnswer(1)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-1">
              <div class="correct-answer">
                ‚úì Resposta Correta: B) Apenas I e III s√£o verdadeiras
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que s√£o algoritmos de busca informada?</strong
                ><br />
                S√£o algoritmos que usam informa√ß√£o adicional (heur√≠stica) para
                guiar a busca de forma mais eficiente que buscas cegas.
                Exemplos: A*, busca gulosa.<br /><br />

                <strong>An√°lise das afirmativas:</strong><br />
                <strong>I. VERDADEIRA ‚úì</strong> - O A* usa f(n) = g(n) + h(n),
                onde g(n) √© o custo real at√© o n√≥ e h(n) √© a heur√≠stica. Se h(n)
                for admiss√≠vel (nunca superestima), o A* SEMPRE encontra o
                caminho mais curto (√© √≥timo) e sempre encontra solu√ß√£o se ela
                existir (√© completo).<br /><br />

                <strong>II. FALSA ‚úó</strong> - A busca gulosa usa APENAS h(n),
                ignorando o custo j√° percorrido. Ela √© r√°pida mas pode cair em
                caminhos ruins. N√£o garante solu√ß√£o √≥tima! Exemplo: pode
                escolher um caminho que parece bom no in√≠cio mas √© p√©ssimo no
                total.<br /><br />

                <strong>III. VERDADEIRA ‚úì</strong> - Heur√≠stica consistente
                (h(n) ‚â§ custo(n,n') + h(n')) sempre √© admiss√≠vel. Mas uma
                heur√≠stica admiss√≠vel pode n√£o ser consistente. Consist√™ncia √©
                uma propriedade mais forte.
              </div>
            </div>
          </div>
        </div>

        <!-- 2 -->
        <div class="question">
          <div class="question-title">2)</div>
          <div class="question-text">
            No contexto de Redes Neurais Convolucionais (CNNs), qual das
            seguintes afirma√ß√µes sobre opera√ß√µes de pooling est√° INCORRETA?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q2" value="A" /> A) Max pooling
              seleciona o valor m√°ximo em cada regi√£o da janela</label
            >
            <label
              ><input type="radio" name="q2" value="B" /> B) Average pooling
              calcula a m√©dia dos valores na janela</label
            >
            <label
              ><input type="radio" name="q2" value="C" /> C) Pooling reduz a
              dimensionalidade espacial da representa√ß√£o</label
            >
            <label
              ><input type="radio" name="q2" value="D" /> D) Pooling aumenta o
              n√∫mero de par√¢metros trein√°veis da rede</label
            >
            <label
              ><input type="radio" name="q2" value="E" /> E) Pooling ajuda a
              criar invari√¢ncia a pequenas transla√ß√µes</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-2"
              onclick="toggleAnswer(2)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-2">
              <div class="correct-answer">
                ‚úì Resposta Correta: D) Pooling aumenta o n√∫mero de par√¢metros
                trein√°veis da rede
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© Pooling em CNNs?</strong><br />
                Pooling √© uma opera√ß√£o que reduz o tamanho das imagens/features
                em uma CNN. Imagina uma janela 2x2 que desliza pela imagem
                pegando resumos de cada regi√£o.<br /><br />

                <strong>Por que a alternativa D est√° INCORRETA:</strong><br />
                Pooling N√ÉO tem par√¢metros trein√°veis! √â s√≥ uma opera√ß√£o
                matem√°tica fixa (tipo tirar o m√°ximo ou m√©dia). N√£o aprende
                nada, n√£o tem pesos.<br /><br />

                <strong>As outras alternativas explicadas:</strong><br />
                ‚Ä¢ <strong>Max pooling:</strong> Pega o maior valor da janela
                (ex: [1,2,3,4] ‚Üí 4)<br />
                ‚Ä¢ <strong>Average pooling:</strong> Calcula a m√©dia (ex:
                [1,2,3,4] ‚Üí 2.5)<br />
                ‚Ä¢ <strong>Reduz dimensionalidade:</strong> Uma imagem 100x100
                vira 50x50 ap√≥s pooling 2x2<br />
                ‚Ä¢ <strong>Invari√¢ncia:</strong> Se a imagem mover 1 pixel, o max
                pooling pode dar o mesmo resultado<br /><br />

                <strong>üí° Resumo:</strong> Pooling simplifica a rede, reduz
                custo computacional e ajuda a generalizar, mas n√£o adiciona
                complexidade ao modelo.
              </div>
            </div>
          </div>
        </div>

        <!-- 3 -->
        <div class="question">
          <div class="question-title">3)</div>
          <div class="question-text">
            Em um problema de classifica√ß√£o multiclasse com 5 classes usando
            Redes Neurais, a camada de sa√≠da utiliza fun√ß√£o de ativa√ß√£o softmax.
            Se as sa√≠das antes da softmax (logits) s√£o [2.0, 1.0, 0.1, 3.0,
            0.5], qual propriedade matem√°tica a fun√ß√£o softmax garante?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q3" value="A" /> A) Todas as sa√≠das
              ser√£o exatamente iguais a 0.2</label
            >
            <label
              ><input type="radio" name="q3" value="B" /> B) A soma de todas as
              probabilidades de sa√≠da ser√° igual a 1</label
            >
            <label
              ><input type="radio" name="q3" value="C" /> C) O maior logit
              sempre resultar√° em probabilidade maior que 0.5</label
            >
            <label
              ><input type="radio" name="q3" value="D" /> D) Valores negativos
              de logits resultam em probabilidades negativas</label
            >
            <label
              ><input type="radio" name="q3" value="E" /> E) A diferen√ßa entre
              probabilidades consecutivas ser√° constante</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-3"
              onclick="toggleAnswer(3)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-3">
              <div class="correct-answer">
                ‚úì Resposta Correta: B) A soma de todas as probabilidades de
                sa√≠da ser√° igual a 1
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© Softmax?</strong><br />
                Softmax transforma n√∫meros quaisquer (logits) em probabilidades
                v√°lidas. √â usada na √∫ltima camada de redes neurais para
                classifica√ß√£o multiclasse.<br /><br />

                <strong>F√≥rmula:</strong> softmax(x_i) = e^(x_i) / Œ£(e^(x_j))<br /><br />

                <strong
                  >Com os valores do exemplo [2.0, 1.0, 0.1, 3.0, 0.5]:</strong
                ><br />
                Ap√≥s softmax: [0.10, 0.04, 0.01, 0.28, 0.02] (valores
                aproximados)<br />
                Soma = 0.10 + 0.04 + 0.01 + 0.28 + 0.02 = 1.00 ‚úì<br /><br />

                <strong>Por que B est√° correta:</strong><br />
                A propriedade FUNDAMENTAL do softmax √© que a soma sempre d√° 1,
                transformando qualquer vetor em uma distribui√ß√£o de
                probabilidade v√°lida. Assim voc√™ pode dizer "30% de chance de
                ser classe A, 50% classe B, 20% classe C".<br /><br />

                <strong>Por que as outras est√£o erradas:</strong><br />
                ‚Ä¢ A) N√ÉO ficam iguais (0.2 seria se todos logits fossem
                iguais)<br />
                ‚Ä¢ C) O maior pode dar < 0.5 se houver muitas classes pr√≥ximas<br />
                ‚Ä¢ D) Softmax SEMPRE d√° valores positivos (usa exponencial)<br />
                ‚Ä¢ E) As diferen√ßas n√£o s√£o constantes, dependem dos valores
              </div>
            </div>
          </div>
        </div>

        <!-- 4 -->
        <div class="question">
          <div class="question-title">4)</div>
          <div class="question-text">
            Considere um problema de aprendizado por refor√ßo onde um agente
            navega em um ambiente com estados S, a√ß√µes A, e fun√ß√£o de recompensa
            R. Qual das seguintes afirma√ß√µes sobre Q-learning est√° correta?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q4" value="A" /> A) Q-learning √© um
              m√©todo on-policy que requer seguir a pol√≠tica sendo
              aprendida</label
            >
            <label
              ><input type="radio" name="q4" value="B" /> B) Q-learning converge
              para a pol√≠tica √≥tima apenas em ambientes determin√≠sticos</label
            >
            <label
              ><input type="radio" name="q4" value="C" /> C) A equa√ß√£o de
              atualiza√ß√£o do Q-learning usa o valor m√°ximo de Q para o pr√≥ximo
              estado</label
            >
            <label
              ><input type="radio" name="q4" value="D" /> D) Q-learning n√£o pode
              ser usado em ambientes com espa√ßos de estados cont√≠nuos</label
            >
            <label
              ><input type="radio" name="q4" value="E" /> E) O fator de desconto
              &gamma; deve sempre ser igual a 1 para converg√™ncia</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-4"
              onclick="toggleAnswer(4)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-4">
              <div class="correct-answer">
                ‚úì Resposta Correta: C) A equa√ß√£o de atualiza√ß√£o do Q-learning
                usa o valor m√°ximo de Q para o pr√≥ximo estado
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© Q-learning?</strong><br />
                √â um algoritmo de Aprendizado por Refor√ßo onde um agente aprende
                a tomar decis√µes interagindo com um ambiente. O "Q" representa
                "qualidade" de uma a√ß√£o em determinado estado.<br /><br />

                <strong>F√≥rmula do Q-learning:</strong><br />
                Q(s,a) ‚Üê Q(s,a) + Œ±[r + Œ≥¬∑max Q(s',a') - Q(s,a)]<br />
                ‚Ä¢ s = estado atual, a = a√ß√£o tomada<br />
                ‚Ä¢ r = recompensa recebida<br />
                ‚Ä¢ s' = pr√≥ximo estado<br />
                ‚Ä¢ max Q(s',a') = MELHOR a√ß√£o poss√≠vel no pr√≥ximo estado<br />
                ‚Ä¢ Œ± = taxa de aprendizado, Œ≥ = fator de desconto<br /><br />

                <strong>Por que C est√° correta:</strong><br />
                A atualiza√ß√£o usa o M√ÅXIMO Q do pr√≥ximo estado. Isso √© otimista:
                "assuma que voc√™ vai tomar a melhor decis√£o no futuro".<br /><br />

                <strong>Por que as outras est√£o erradas:</strong><br />
                ‚Ä¢ A) Q-learning √© OFF-policy (n√£o precisa seguir a pol√≠tica que
                est√° aprendendo)<br />
                ‚Ä¢ B) Funciona SIM em ambientes estoc√°sticos (com
                aleatoriedade)<br />
                ‚Ä¢ D) Pode ser usado em espa√ßos cont√≠nuos (com Deep
                Q-Learning/DQN)<br />
                ‚Ä¢ E) Œ≥ pode ser < 1 (comum: 0.9 a 0.99). Œ≥=1 pode n√£o convergir
                em problemas infinitos
              </div>
            </div>
          </div>
        </div>

        <!-- 5 -->
        <div class="question">
          <div class="question-title">5)</div>
          <div class="question-text">
            Em √°rvores de decis√£o, o fen√¥meno de overfitting pode ser controlado
            atrav√©s de t√©cnicas de poda. Qual das seguintes N√ÉO √© uma estrat√©gia
            efetiva para reduzir overfitting em √°rvores de decis√£o?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q5" value="A" /> A) Limitar a
              profundidade m√°xima da √°rvore</label
            >
            <label
              ><input type="radio" name="q5" value="B" /> B) Estabelecer um
              n√∫mero m√≠nimo de amostras por folha</label
            >
            <label
              ><input type="radio" name="q5" value="C" /> C) Aumentar
              indefinidamente o n√∫mero de n√≠veis da √°rvore</label
            >
            <label
              ><input type="radio" name="q5" value="D" /> D) Usar poda
              p√≥s-crescimento (post-pruning)</label
            >
            <label
              ><input type="radio" name="q5" value="E" /> E) Definir um ganho
              m√≠nimo de informa√ß√£o para divis√£o de n√≥s</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-5"
              onclick="toggleAnswer(5)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-5">
              <div class="correct-answer">
                ‚úì Resposta Correta: C) Aumentar indefinidamente o n√∫mero de
                n√≠veis da √°rvore
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© Overfitting?</strong><br />
                Overfitting acontece quando o modelo "decora" os dados de treino
                mas n√£o generaliza para dados novos. √â tipo estudar decorando as
                respostas sem entender - funciona na prova que voc√™ viu, mas n√£o
                em quest√µes novas.<br /><br />

                <strong>√Årvores de Decis√£o:</strong><br />
                S√£o modelos que fazem perguntas sequenciais tipo: "idade > 30?"
                ‚Üí sim/n√£o ‚Üí pr√≥xima pergunta. Quanto mais profunda a √°rvore,
                mais espec√≠ficas as regras.<br /><br />

                <strong
                  >Por que C est√° INCORRETA (n√£o reduz overfitting):</strong
                ><br />
                √Årvore muito profunda = regras super espec√≠ficas = MEMORIZA os
                dados! Exemplo: "Se idade=27 E sal√°rio=3542 E cidade=X E choveu
                ter√ßa..." ‚Üí isso √© overfit puro!<br /><br />

                <strong>T√©cnicas que REALMENTE reduzem overfitting:</strong
                ><br />
                ‚Ä¢ <strong>A) Profundidade m√°xima:</strong> "Pare em 5 n√≠veis" -
                for√ßa generaliza√ß√£o<br />
                ‚Ä¢ <strong>B) Amostras m√≠nimas:</strong> "S√≥ divida se tiver 20+
                exemplos" - evita regras para casos raros<br />
                ‚Ä¢ <strong>D) Poda:</strong> Crescer a √°rvore e depois cortar
                galhos ruins<br />
                ‚Ä¢ <strong>E) Ganho m√≠nimo:</strong> "S√≥ divida se melhorar
                bastante" - evita divis√µes in√∫teis<br /><br />

                <strong>üí° Regra de ouro:</strong> √Årvore grande = decoreba.
                √Årvore controlada = aprendizado real.
              </div>
            </div>
          </div>
        </div>

        <!-- 6 -->
        <div class="question">
          <div class="question-title">6)</div>
          <div class="question-text">
            No contexto de Support Vector Machines (SVM), o que acontece quando
            o par√¢metro de regulariza√ß√£o C √© aumentado significativamente?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q6" value="A" /> A) A margem de
              separa√ß√£o aumenta e o modelo tolera mais erros de
              classifica√ß√£o</label
            >
            <label
              ><input type="radio" name="q6" value="B" /> B) A margem diminui e
              o modelo se torna mais sens√≠vel a outliers (overfitting)</label
            >
            <label
              ><input type="radio" name="q6" value="C" /> C) O n√∫mero de support
              vectors aumenta proporcionalmente</label
            >
            <label
              ><input type="radio" name="q6" value="D" /> D) O modelo se torna
              equivalente a uma regress√£o linear</label
            >
            <label
              ><input type="radio" name="q6" value="E" /> E) A complexidade
              computacional diminui exponencialmente</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-6"
              onclick="toggleAnswer(6)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-6">
              <div class="correct-answer">
                ‚úì Resposta Correta: B) A margem diminui e o modelo se torna mais
                sens√≠vel a outliers (overfitting)
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© SVM (Support Vector Machine)?</strong><br />
                SVM √© um algoritmo que tra√ßa uma linha (ou hiperplano) para
                separar duas classes. O objetivo √© encontrar a linha que deixa a
                MAIOR margem poss√≠vel entre as classes.<br /><br />

                <strong>O que √© a margem?</strong><br />
                √â a "faixa de seguran√ßa" entre a linha de separa√ß√£o e os pontos
                mais pr√≥ximos de cada classe. Margem grande = modelo mais
                confi√°vel.<br /><br />

                <strong>O que √© o par√¢metro C?</strong><br />
                C controla a toler√¢ncia a erros:<br />
                ‚Ä¢ <strong>C pequeno (ex: 0.1):</strong> "T√° ok errar alguns
                pontos, quero margem GRANDE" ‚Üí generaliza melhor<br />
                ‚Ä¢ <strong>C grande (ex: 100):</strong> "N√ÉO PODE ERRAR!" ‚Üí
                margem pequena, passa pertinho dos pontos ‚Üí OVERFITTING<br /><br />

                <strong>Por que B est√° correta:</strong><br />
                Quando C aumenta muito, o modelo tenta classificar PERFEITAMENTE
                todos os pontos de treino, incluindo outliers (pontos
                estranhos/ru√≠do). A margem fica apertada e o modelo fica
                sens√≠vel demais.<br /><br />

                <strong>Analogia:</strong><br />
                C alto = andar numa corda bamba fininha (margem pequena,
                perigoso)<br />
                C baixo = andar numa ponte larga (margem grande, seguro)<br /><br />

                <strong>Por que as outras est√£o erradas:</strong><br />
                ‚Ä¢ A) Margem DIMINUI (n√£o aumenta) e tolera MENOS erros<br />
                ‚Ä¢ C) N√∫mero de support vectors geralmente diminui<br />
                ‚Ä¢ D) SVM nunca vira regress√£o linear<br />
                ‚Ä¢ E) Complexidade aumenta (n√£o diminui)
              </div>
            </div>
          </div>
        </div>

        <!-- 7 -->
        <div class="question">
          <div class="question-title">7)</div>
          <div class="question-text">
            Em redes neurais recorrentes (RNNs), o problema de gradientes que
            explodem (exploding gradients) pode ser mitigado atrav√©s de:
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q7" value="A" /> A) Aumento da taxa de
              aprendizado</label
            >
            <label
              ><input type="radio" name="q7" value="B" /> B) Remo√ß√£o de todas as
              camadas ocultas</label
            >
            <label
              ><input type="radio" name="q7" value="C" /> C) Gradient clipping
              (limita√ß√£o do gradiente)</label
            >
            <label
              ><input type="radio" name="q7" value="D" /> D) Uso exclusivo de
              fun√ß√£o de ativa√ß√£o sigmoid</label
            >
            <label
              ><input type="radio" name="q7" value="E" /> E) Aumento do tamanho
              do batch</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-7"
              onclick="toggleAnswer(7)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-7">
              <div class="correct-answer">
                ‚úì Resposta Correta: C) Gradient clipping (limita√ß√£o do
                gradiente)
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que s√£o RNNs?</strong><br />
                Redes Neurais Recorrentes processam sequ√™ncias (texto, √°udio,
                s√©ries temporais). Elas t√™m "mem√≥ria" para lembrar informa√ß√£o
                anterior.<br /><br />

                <strong>O que s√£o gradientes?</strong><br />
                Durante o treino, o modelo calcula gradientes (derivadas) para
                saber como ajustar os pesos. √â tipo "quanto devo mexer em cada
                bot√£o para melhorar".<br /><br />

                <strong
                  >Problema: Exploding Gradients (Gradientes Explosivos)</strong
                ><br />
                Em RNNs longas, os gradientes podem EXPLODIR (ficar GIGANTES
                tipo 10‚Åπ‚Å∞). Isso causa:<br />
                ‚Ä¢ Valores num√©ricos infinitos (NaN)<br />
                ‚Ä¢ Pesos malucos<br />
                ‚Ä¢ Treino que n√£o converge<br /><br />

                <strong>Por que C est√° correta: Gradient Clipping</strong><br />
                √â tipo colocar um limitador de velocidade:<br />
                "Se o gradiente passar de 5, corta pra 5"<br />
                Pseudo-c√≥digo: if (gradient > 5): gradient = 5<br /><br />
                Isso previne updates muito grandes que desestabilizam o treino.
                √â a solu√ß√£o padr√£o para RNNs!<br /><br />

                <strong>Por que as outras est√£o erradas:</strong><br />
                ‚Ä¢ A) Aumentar taxa de aprendizado PIORA o problema (updates
                ainda maiores!)<br />
                ‚Ä¢ B) Remover camadas destr√≥i o modelo<br />
                ‚Ä¢ D) Sigmoid n√£o resolve (e tem outros problemas)<br />
                ‚Ä¢ E) Tamanho do batch n√£o afeta gradientes explosivos<br /><br />

                <strong>Outras solu√ß√µes:</strong> Usar LSTM ou GRU (arquiteturas
                que amenizam o problema naturalmente)
              </div>
            </div>
          </div>
        </div>

        <!-- 8 -->
        <div class="question">
          <div class="question-title">8)</div>
          <div class="question-text">
            No algoritmo de clustering K-means, considere as seguintes
            afirmativas:<br />
            I. O resultado final depende da inicializa√ß√£o dos centroides.<br />
            II. O algoritmo sempre converge para o √≥timo global.<br />
            III. √â necess√°rio especificar o n√∫mero de clusters K
            antecipadamente.<br />
            Assinale a alternativa correta:
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q8" value="A" /> A) Apenas I √©
              verdadeira</label
            >
            <label
              ><input type="radio" name="q8" value="B" /> B) Apenas I e II s√£o
              verdadeiras</label
            >
            <label
              ><input type="radio" name="q8" value="C" /> C) Apenas I e III s√£o
              verdadeiras</label
            >
            <label
              ><input type="radio" name="q8" value="D" /> D) Apenas II e III s√£o
              verdadeiras</label
            >
            <label
              ><input type="radio" name="q8" value="E" /> E) Todas s√£o
              verdadeiras</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-8"
              onclick="toggleAnswer(8)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-8">
              <div class="correct-answer">
                ‚úì Resposta Correta: C) Apenas I e III s√£o verdadeiras
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© K-means?</strong><br />
                √â um algoritmo de clustering (agrupamento) que divide dados em K
                grupos. Exemplo: agrupar clientes em 3 perfis (economizadores,
                gastadores, moderados).<br /><br />

                <strong>Como funciona:</strong><br />
                1. Escolhe K pontos aleat√≥rios como centr√≥ides (centros dos
                grupos)<br />
                2. Associa cada ponto ao centr√≥ide mais pr√≥ximo<br />
                3. Recalcula os centr√≥ides (m√©dia dos pontos do grupo)<br />
                4. Repete at√© estabilizar<br /><br />

                <strong>An√°lise das afirmativas:</strong><br /><br />
                <strong>I. VERDADEIRA ‚úì</strong> - "Resultado depende da
                inicializa√ß√£o"<br />
                Se come√ßar com centr√≥ides ruins, pode ficar preso em solu√ß√£o
                ruim. Por isso:<br />
                ‚Ä¢ Roda v√°rias vezes com inicializa√ß√µes diferentes<br />
                ‚Ä¢ Usa K-means++ (escolha inteligente dos centr√≥ides iniciais)<br /><br />

                <strong>II. FALSA ‚úó</strong> - "Sempre converge para √≥timo
                global"<br />
                ERRADO! K-means converge apenas para √≥timo LOCAL (melhor solu√ß√£o
                na vizinhan√ßa).<br />
                Analogia: Voc√™ procura o ponto mais alto, mas pode ficar preso
                num morrinho ao inv√©s de achar a montanha gigante!<br /><br />

                <strong>III. VERDADEIRA ‚úì</strong> - "Precisa especificar K"<br />
                Voc√™ DEVE dizer quantos grupos quer ANTES de rodar. N√£o descobre
                automaticamente.<br /><br />

                <strong>Como escolher K?</strong><br />
                ‚Ä¢ M√©todo do cotovelo (elbow method)<br />
                ‚Ä¢ Silhouette score<br />
                ‚Ä¢ Dom√≠nio do problema ("meu neg√≥cio tem 3 tipos de cliente")
              </div>
            </div>
          </div>
        </div>

        <!-- 9 -->
        <div class="question">
          <div class="question-title">9)</div>
          <div class="question-text">
            Em um modelo de regress√£o log√≠stica para classifica√ß√£o bin√°ria, qual
            fun√ß√£o de perda (loss function) √© tipicamente utilizada?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q9" value="A" /> A) Erro quadr√°tico
              m√©dio (MSE)</label
            >
            <label
              ><input type="radio" name="q9" value="B" /> B) Entropia cruzada
              bin√°ria (Binary Cross-Entropy)</label
            >
            <label
              ><input type="radio" name="q9" value="C" /> C) Erro absoluto m√©dio
              (MAE)</label
            >
            <label
              ><input type="radio" name="q9" value="D" /> D) Dist√¢ncia
              euclidiana</label
            >
            <label
              ><input type="radio" name="q9" value="E" /> E) Coeficiente de
              correla√ß√£o de Pearson</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-9"
              onclick="toggleAnswer(9)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-9">
              <div class="correct-answer">
                ‚úì Resposta Correta: B) Entropia cruzada bin√°ria (Binary
                Cross-Entropy)
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© Regress√£o Log√≠stica?</strong><br />
                Apesar do nome "regress√£o", √© usado para CLASSIFICA√á√ÉO bin√°ria
                (sim/n√£o, spam/n√£o-spam, doente/saud√°vel).<br />
                Usa a fun√ß√£o sigmoid para dar probabilidades entre 0 e 1.<br /><br />

                <strong>O que √© Fun√ß√£o de Perda (Loss Function)?</strong><br />
                Mede "qu√£o errado" o modelo est√°. O treino tenta MINIMIZAR essa
                fun√ß√£o.<br /><br />

                <strong
                  >Por que B est√° correta: Binary Cross-Entropy (BCE)</strong
                ><br />
                Tamb√©m chamada de Log Loss. F√≥rmula:<br />
                BCE = -[y¬∑log(p) + (1-y)¬∑log(1-p)]<br /><br />
                Onde:<br />
                ‚Ä¢ y = classe real (0 ou 1)<br />
                ‚Ä¢ p = probabilidade prevista (0 a 1)<br /><br />
                <strong>Exemplo pr√°tico:</strong><br />
                Classe real = 1 (spam), Modelo previu p=0.9<br />
                BCE = -[1¬∑log(0.9)] = 0.105 (erro pequeno, bom!)<br /><br />
                Classe real = 1 (spam), Modelo previu p=0.1<br />
                BCE = -[1¬∑log(0.1)] = 2.303 (erro grande, ruim!)<br /><br />

                <strong>Por que BCE √© ideal para classifica√ß√£o:</strong><br />
                ‚Ä¢ Penaliza muito predi√ß√µes confiantes e erradas<br />
                ‚Ä¢ Trabalha naturalmente com probabilidades<br />
                ‚Ä¢ Tem propriedades matem√°ticas que facilitam otimiza√ß√£o<br /><br />

                <strong>Por que as outras n√£o s√£o ideais:</strong><br />
                ‚Ä¢ A) MSE √© para regress√£o (prever n√∫meros cont√≠nuos tipo
                pre√ßos)<br />
                ‚Ä¢ C) MAE tamb√©m √© para regress√£o<br />
                ‚Ä¢ D) Dist√¢ncia euclidiana n√£o √© usada como loss<br />
                ‚Ä¢ E) Correla√ß√£o de Pearson √© m√©trica, n√£o loss function
              </div>
            </div>
          </div>
        </div>

        <!-- 10 -->
        <div class="question">
          <div class="question-title">10)</div>
          <div class="question-text">
            No contexto de transfer learning com redes neurais profundas, qual
            estrat√©gia √© mais apropriada quando o novo dataset √© pequeno e
            similar ao dataset original?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q10" value="A" /> A) Treinar toda a
              rede do zero com inicializa√ß√£o aleat√≥ria</label
            >
            <label
              ><input type="radio" name="q10" value="B" /> B) Congelar todas as
              camadas exceto a camada de sa√≠da e treinar apenas esta</label
            >
            <label
              ><input type="radio" name="q10" value="C" /> C) Descartar a rede
              pr√©-treinada e usar um modelo mais simples</label
            >
            <label
              ><input type="radio" name="q10" value="D" /> D) Treinar apenas as
              primeiras camadas convolucionais</label
            >
            <label
              ><input type="radio" name="q10" value="E" /> E) Usar apenas data
              augmentation sem transfer learning</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-10"
              onclick="toggleAnswer(10)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-10">
              <div class="correct-answer">
                ‚úì Resposta Correta: B) Congelar todas as camadas exceto a camada
                de sa√≠da e treinar apenas esta
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© Transfer Learning?</strong><br />
                √â tipo "copiar a li√ß√£o do nerd da sala". Voc√™ pega uma rede
                neural j√° treinada (ex: no ImageNet com milh√µes de imagens) e
                adapta para seu problema.<br /><br />

                <strong>Por que usar Transfer Learning?</strong><br />
                Treinar do zero precisa de:<br />
                ‚Ä¢ MUITO tempo (dias/semanas)<br />
                ‚Ä¢ MUITOS dados (milh√µes de exemplos)<br />
                ‚Ä¢ MUITA GPU/dinheiro<br /><br />
                Com transfer learning: horas + poucos dados + 1 GPU =
                sucesso!<br /><br />

                <strong>Cen√°rio da quest√£o:</strong><br />
                ‚Ä¢ Dataset PEQUENO (poucos exemplos)<br />
                ‚Ä¢ SIMILAR ao original (ex: ambos s√£o fotos de animais)<br /><br />

                <strong>Por que B √© a melhor estrat√©gia:</strong><br />
                <strong>CONGELAR</strong> = n√£o treinar, manter pesos fixos<br /><br />
                As camadas convolucionais iniciais j√° aprenderam features
                gerais:<br />
                ‚Ä¢ Camada 1: detecta bordas, linhas<br />
                ‚Ä¢ Camada 2: detecta texturas, formas simples<br />
                ‚Ä¢ Camada 3: detecta partes de objetos (olhos, orelhas)<br />
                ‚Ä¢ √öltima camada: classifica√ß√£o espec√≠fica ("gato" vs
                "cachorro")<br /><br />
                Como o dataset √© similar, as features j√° s√£o √∫teis! S√≥
                precisamos adaptar a CLASSIFICA√á√ÉO FINAL.<br /><br />
                <strong>Vantagens:</strong><br />
                ‚Ä¢ R√°pido (treina poucos pesos)<br />
                ‚Ä¢ N√£o d√° overfitting (poucos par√¢metros atualizados)<br />
                ‚Ä¢ Funciona com poucos dados<br /><br />

                <strong>Matriz de decis√£o:</strong><br />
                Dataset pequeno + Similar ‚Üí Congelar tudo exceto sa√≠da (resposta
                B)<br />
                Dataset pequeno + Diferente ‚Üí Congelar quase tudo<br />
                Dataset grande + Similar ‚Üí Fine-tuning (treinar √∫ltimas
                camadas)<br />
                Dataset grande + Diferente ‚Üí Treinar tudo do zero<br /><br />

                <strong>Por que as outras est√£o erradas:</strong><br />
                ‚Ä¢ A) Treinar do zero = precisa de MUITO mais dados (vai dar
                overfitting!)<br />
                ‚Ä¢ C) Jogar fora conhecimento valioso<br />
                ‚Ä¢ D) Camadas iniciais s√£o as que J√Å funcionam bem<br />
                ‚Ä¢ E) Data augmentation ajuda mas n√£o substitui transfer learning
              </div>
            </div>
          </div>
        </div>

        <!-- 11 -->
        <div class="question">
          <div class="question-title">11)</div>
          <div class="question-text">
            Em um sistema especialista baseado em regras, qual componente √©
            respons√°vel por controlar a aplica√ß√£o das regras e resolver
            conflitos quando m√∫ltiplas regras podem ser ativadas
            simultaneamente?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q11" value="A" /> A) Base de
              conhecimento</label
            >
            <label
              ><input type="radio" name="q11" value="B" /> B) Motor de
              infer√™ncia</label
            >
            <label
              ><input type="radio" name="q11" value="C" /> C) Interface do
              usu√°rio</label
            >
            <label
              ><input type="radio" name="q11" value="D" /> D) Base de
              dados</label
            >
            <label
              ><input type="radio" name="q11" value="E" /> E) M√≥dulo de
              explica√ß√£o</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-11"
              onclick="toggleAnswer(11)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-11">
              <div class="correct-answer">
                ‚úì Resposta Correta: B) Motor de infer√™ncia
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© um Sistema Especialista?</strong><br />
                √â um programa que imita a decis√£o de um especialista humano.
                Exemplo: sistema que diagnostica doen√ßas como um m√©dico.<br /><br />

                <strong>Componentes principais:</strong><br /><br />
                <strong>1. Base de Conhecimento</strong><br />
                Armazena as REGRAS (tipo "SE-ENT√ÉO"):<br />
                ‚Ä¢ SE febre > 38¬∞C E dor_de_garganta ENT√ÉO poss√≠vel_gripe<br />
                ‚Ä¢ SE poss√≠vel_gripe E tosse ENT√ÉO recomendar_m√©dico<br /><br />

                <strong>2. Base de Dados (Working Memory)</strong><br />
                Armazena os FATOS atuais:<br />
                ‚Ä¢ febre = 39¬∞C<br />
                ‚Ä¢ dor_de_garganta = sim<br />
                ‚Ä¢ tosse = n√£o<br /><br />

                <strong
                  >3. Motor de Infer√™ncia (Inference Engine) ‚úì RESPOSTA</strong
                ><br />
                √â o "c√©rebro" do sistema! Ele:<br />
                ‚Ä¢ <strong>Aplica as regras:</strong> Verifica quais regras podem
                ser ativadas com os fatos atuais<br />
                ‚Ä¢ <strong>Resolve conflitos:</strong> Se 3 regras podem ser
                ativadas, qual usar primeiro?<br />
                ‚Ä¢ <strong>Controla o fluxo:</strong> Forward chaining (dos fatos
                √† conclus√£o) ou backward chaining (da conclus√£o aos fatos)<br /><br />

                <strong>Exemplo de conflito:</strong><br />
                Regra A: SE febre ENT√ÉO dar_rem√©dio_A<br />
                Regra B: SE febre E idade>60 ENT√ÉO dar_rem√©dio_B<br />
                Ambas podem ser ativadas! O motor de infer√™ncia decide qual
                executar baseado em prioridades.<br /><br />

                <strong>Estrat√©gias de resolu√ß√£o de conflitos:</strong><br />
                ‚Ä¢ Prioridade por especificidade (regra mais espec√≠fica
                primeiro)<br />
                ‚Ä¢ Ordem de defini√ß√£o<br />
                ‚Ä¢ Regras mais recentes primeiro<br /><br />

                <strong>4. Interface do Usu√°rio</strong><br />
                Permite intera√ß√£o (perguntas e respostas)<br /><br />

                <strong>5. M√≥dulo de Explica√ß√£o</strong><br />
                Explica POR QUE chegou em determinada conclus√£o<br /><br />

                <strong>üí° Resumo:</strong> O Motor de Infer√™ncia √© quem "pensa"
                e decide qual regra usar!
              </div>
            </div>
          </div>
        </div>

        <!-- 12 -->
        <div class="question">
          <div class="question-title">12)</div>
          <div class="question-text">
            Considere um problema de classifica√ß√£o com dataset desbalanceado
            (95% classe negativa, 5% classe positiva). Qual t√©cnica de
            balanceamento N√ÉO √© apropriada para melhorar o desempenho do modelo?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q12" value="A" /> A) SMOTE (Synthetic
              Minority Over-sampling Technique)</label
            >
            <label
              ><input type="radio" name="q12" value="B" /> B) Undersampling da
              classe majorit√°ria</label
            >
            <label
              ><input type="radio" name="q12" value="C" /> C) Ajuste de pesos
              das classes na fun√ß√£o de perda</label
            >
            <label
              ><input type="radio" name="q12" value="D" /> D) Ignorar
              completamente o desbalanceamento e usar apenas acur√°cia</label
            >
            <label
              ><input type="radio" name="q12" value="E" /> E) Ensemble de
              modelos com diferentes propor√ß√µes de classes</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-12"
              onclick="toggleAnswer(12)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-12">
              <div class="correct-answer">
                ‚úì Resposta Correta: D) Ignorar completamente o desbalanceamento
                e usar apenas acur√°cia
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© Dataset Desbalanceado?</strong><br />
                Quando as classes t√™m quantidades muito diferentes. No exemplo:
                95% negativos, 5% positivos.<br /><br />
                <strong>Exemplos reais:</strong><br />
                ‚Ä¢ Detec√ß√£o de fraude: 99% transa√ß√µes normais, 1% fraudes<br />
                ‚Ä¢ Diagn√≥stico de doen√ßa rara: 98% saud√°veis, 2% doentes<br />
                ‚Ä¢ Spam: 90% emails normais, 10% spam<br /><br />

                <strong>O GRANDE PROBLEMA:</strong><br />
                Um modelo "burro" que SEMPRE preveja "negativo" teria 95% de
                acur√°cia!<br />
                Mas ele √© INUTIL - n√£o detecta nenhum caso positivo!<br /><br />

                <strong>Por que D est√° INCORRETA (n√£o √© apropriada):</strong
                ><br />
                Acur√°cia = (acertos totais) / (total de exemplos)<br /><br />
                <strong>Exemplo pr√°tico:</strong><br />
                1000 exemplos: 950 negativos, 50 positivos<br /><br />
                Modelo idiota: sempre preveja "negativo"<br />
                ‚Ä¢ Acertos: 950 (todos os negativos)<br />
                ‚Ä¢ Erros: 50 (todos os positivos)<br />
                ‚Ä¢ Acur√°cia: 950/1000 = 95% üéâ<br /><br />
                MAS ELE N√ÉO SERVE PRA NADA! Nunca detecta fraudes/doen√ßas!<br /><br />

                <strong>M√©tricas corretas para dados desbalanceados:</strong
                ><br />
                ‚Ä¢ <strong>Precision:</strong> Dos que previ positivo, quantos
                acertei?<br />
                ‚Ä¢ <strong>Recall:</strong> Dos positivos reais, quantos
                detectei?<br />
                ‚Ä¢ <strong>F1-Score:</strong> M√©dia harm√¥nica de precision e
                recall<br />
                ‚Ä¢ <strong>AUC-ROC:</strong> √Årea sob a curva ROC<br /><br />

                <strong>T√©cnicas APROPRIADAS (as outras alternativas):</strong
                ><br /><br />
                <strong>A) SMOTE ‚úì</strong><br />
                Cria exemplos sint√©ticos da classe minorit√°ria interpolando
                entre exemplos existentes.<br /><br />
                <strong>B) Undersampling ‚úì</strong><br />
                Remove exemplos da classe majorit√°ria para equilibrar.<br /><br />
                <strong>C) Ajuste de pesos ‚úì</strong><br />
                D√° peso maior aos erros da classe minorit√°ria na fun√ß√£o de
                perda.<br />
                Ex: erro em positivo conta 19x mais que erro em negativo.<br /><br />
                <strong>E) Ensemble ‚úì</strong><br />
                Treina v√°rios modelos com diferentes balan√ßos e combina
                resultados.<br /><br />

                <strong>üí° Regra de ouro:</strong> Em dados desbalanceados,
                acur√°cia MENTE! Use outras m√©tricas!
              </div>
            </div>
          </div>
        </div>

        <!-- 13 -->
        <div class="question">
          <div class="question-title">13)</div>
          <div class="question-text">
            No algoritmo de Gradient Boosting, qual das seguintes afirma√ß√µes
            est√° CORRETA?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q13" value="A" /> A) Todos os modelos
              base s√£o treinados em paralelo de forma independente</label
            >
            <label
              ><input type="radio" name="q13" value="B" /> B) Cada novo modelo √©
              treinado para corrigir os erros dos modelos anteriores</label
            >
            <label
              ><input type="radio" name="q13" value="C" /> C) O resultado final
              √© sempre a m√©dia simples de todos os modelos</label
            >
            <label
              ><input type="radio" name="q13" value="D" /> D) Gradient Boosting
              √© menos propenso a overfitting que Random Forest</label
            >
            <label
              ><input type="radio" name="q13" value="E" /> E) A taxa de
              aprendizado n√£o afeta o desempenho final do modelo</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-13"
              onclick="toggleAnswer(13)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-13">
              <div class="correct-answer">
                ‚úì Resposta Correta: B) Cada novo modelo √© treinado para corrigir
                os erros dos modelos anteriores
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© Gradient Boosting?</strong><br />
                √â uma t√©cnica de ensemble (combina v√°rios modelos) onde cada
                modelo novo tenta CORRIGIR os erros do anterior. √â tipo trabalho
                em equipe onde cada pessoa corrige os erros da anterior!<br /><br />

                <strong>Como funciona (analogia simples):</strong><br />
                <strong>Rodada 1:</strong> Modelo previu pre√ßo de casa = $200k
                (real = $250k, erro = +$50k)<br />
                <strong>Rodada 2:</strong> Novo modelo tenta prever o ERRO
                ($50k)<br />
                <strong>Rodada 3:</strong> Outro modelo corrige o erro do modelo
                2<br />
                <strong>Resultado final:</strong> Soma todas as previs√µes (com
                pesos)<br /><br />

                <strong>Por que B est√° correta:</strong><br />
                O "Boosting" em Gradient Boosting significa que cada √°rvore nova
                √© treinada nos RESIDUOS (erros) das anteriores.<br /><br />
                Processo:<br />
                1. Treina modelo 1 nos dados<br />
                2. Calcula erros do modelo 1<br />
                3. Treina modelo 2 para prever esses ERROS<br />
                4. Modelo_final = Modelo1 + Œ±¬∑Modelo2<br />
                5. Repete at√© N modelos<br /><br />

                <strong>Por que as outras est√£o erradas:</strong><br /><br />
                <strong>A) FALSA</strong> - Modelos s√£o treinados
                SEQUENCIALMENTE, n√£o em paralelo!<br />
                (Random Forest treina em paralelo, Boosting √© sequencial)<br /><br />

                <strong>C) FALSA</strong> - Resultado √© SOMA PONDERADA, n√£o
                m√©dia simples<br />
                F√≥rmula: y = f1(x) + Œ±¬∑f2(x) + Œ±¬≤¬∑f3(x) + ...<br />
                Onde Œ± = learning rate (taxa de aprendizado)<br /><br />

                <strong>D) FALSA</strong> - Gradient Boosting √© MAIS propenso a
                overfitting!<br />
                Por qu√™? Cada √°rvore nova se ajusta muito aos dados, inclusive
                ru√≠do.<br />
                Solu√ß√µes: usar learning rate baixo, limitar profundidade das
                √°rvores<br /><br />

                <strong>E) FALSA</strong> - Learning rate √© CRUCIAL!<br />
                ‚Ä¢ Learning rate alto (0.3): R√°pido mas risco de overfitting<br />
                ‚Ä¢ Learning rate baixo (0.01): Lento mas generaliza melhor<br /><br />

                <strong>Algoritmos famosos de Gradient Boosting:</strong><br />
                ‚Ä¢ XGBoost (muito usado em competi√ß√µes)<br />
                ‚Ä¢ LightGBM (r√°pido)<br />
                ‚Ä¢ CatBoost (bom com dados categ√≥ricos)<br /><br />

                <strong>üí° Compara√ß√£o:</strong><br />
                Random Forest = V√°rios especialistas independentes votam<br />
                Gradient Boosting = Especialistas trabalham em s√©rie, cada um
                corrigindo o anterior
              </div>
            </div>
          </div>
        </div>

        <!-- 14 -->
        <div class="question">
          <div class="question-title">14)</div>
          <div class="question-text">
            Em Processamento de Linguagem Natural (NLP), embeddings de palavras
            como Word2Vec capturam rela√ß√µes sem√¢nticas. Se temos os vetores: rei
            - homem + mulher ‚âà X, qual palavra X representa melhor essa rela√ß√£o
            vetorial?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q14" value="A" /> A) Pr√≠ncipe</label
            >
            <label><input type="radio" name="q14" value="B" /> B) Rainha</label>
            <label
              ><input type="radio" name="q14" value="C" /> C) Princesa</label
            >
            <label
              ><input type="radio" name="q14" value="D" /> D) Monarca</label
            >
            <label
              ><input type="radio" name="q14" value="E" /> E) Imperador</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-14"
              onclick="toggleAnswer(14)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-14">
              <div class="correct-answer">‚úì Resposta Correta: B) Rainha</div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que s√£o Word Embeddings?</strong><br />
                S√£o representa√ß√µes de palavras como VETORES num√©ricos. Palavras
                com significados similares ficam pr√≥ximas no espa√ßo vetorial.<br /><br />

                <strong>Exemplo simples (2D):</strong><br />
                gato = [0.8, 0.2]<br />
                cachorro = [0.9, 0.1]<br />
                carro = [0.1, 0.9]<br /><br />
                Gato e cachorro est√£o perto (ambos animais), carro est√°
                longe!<br /><br />

                <strong>Word2Vec:</strong><br />
                Algoritmo que aprende embeddings treinando em MUITO texto.
                Descobre rela√ß√µes sem√¢nticas incr√≠veis!<br /><br />

                <strong
                  >Por que B est√° correta: A famosa analogia REI-RAINHA</strong
                ><br /><br />
                <strong>Opera√ß√£o vetorial:</strong><br />
                vetor(rei) - vetor(homem) + vetor(mulher) ‚âà vetor(rainha)<br /><br />
                <strong>O que isso significa?</strong><br />
                "Pegue o conceito de rei, remova o aspecto masculino, adicione o
                aspecto feminino = rainha!"<br /><br />

                <strong>Visualiza√ß√£o (simplificada):</strong><br />
                Imagine eixos:<br />
                ‚Ä¢ Eixo X = masculino ‚Üî feminino<br />
                ‚Ä¢ Eixo Y = comum ‚Üî realeza<br /><br />
                homem = [-1, 0] (masculino, comum)<br />
                mulher = [+1, 0] (feminino, comum)<br />
                rei = [-1, +1] (masculino, realeza)<br />
                rainha = [+1, +1] (feminino, realeza)<br /><br />
                rei - homem + mulher = [-1,+1] - [-1,0] + [+1,0] = [+1,+1] =
                rainha ‚úì<br /><br />

                <strong>Outras analogias que funcionam:</strong><br />
                ‚Ä¢ Paris - Fran√ßa + It√°lia ‚âà Roma<br />
                ‚Ä¢ Nadou - Nadar + Correr ‚âà Correu<br />
                ‚Ä¢ Grande - Maior + Pequeno ‚âà Menor<br /><br />

                <strong>Por que isso √© importante?</strong><br />
                Mostra que word embeddings capturam:<br />
                ‚Ä¢ Rela√ß√µes de g√™nero<br />
                ‚Ä¢ Rela√ß√µes geogr√°ficas<br />
                ‚Ä¢ Rela√ß√µes gramaticais<br />
                ‚Ä¢ Rela√ß√µes conceituais<br /><br />

                <strong>Aplica√ß√µes:</strong><br />
                ‚Ä¢ Tradu√ß√£o autom√°tica<br />
                ‚Ä¢ An√°lise de sentimento<br />
                ‚Ä¢ Chatbots<br />
                ‚Ä¢ Busca sem√¢ntica<br /><br />

                <strong>üí° Resumo:</strong> Word2Vec transforma palavras em
                vetores que capturam significa MATEM√ÅTICO das rela√ß√µes entre
                palavras!
              </div>
            </div>
          </div>
        </div>

        <!-- 15 -->
        <div class="question">
          <div class="question-title">15)</div>
          <div class="question-text">
            No contexto de regulariza√ß√£o em aprendizado de m√°quina, qual das
            seguintes afirma√ß√µes sobre L1 (Lasso) e L2 (Ridge) est√° correta?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q15" value="A" /> A) L1 e L2 produzem
              exatamente os mesmos resultados em todos os casos</label
            >
            <label
              ><input type="radio" name="q15" value="B" /> B) L1 tende a
              produzir solu√ß√µes esparsas, zerando alguns pesos</label
            >
            <label
              ><input type="radio" name="q15" value="C" /> C) L2 sempre zera
              mais pesos que L1</label
            >
            <label
              ><input type="radio" name="q15" value="D" /> D) Regulariza√ß√£o L1 e
              L2 aumentam o risco de underfitting em qualquer situa√ß√£o</label
            >
            <label
              ><input type="radio" name="q15" value="E" /> E) L2 √© mais
              eficiente computacionalmente em datasets pequenos que L1</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-15"
              onclick="toggleAnswer(15)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-15">
              <div class="correct-answer">
                ‚úì Resposta Correta: B) L1 tende a produzir solu√ß√µes esparsas,
                zerando alguns pesos
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© Regulariza√ß√£o?</strong><br />
                √â adicionar uma "penalidade" no modelo para evitar que ele fique
                complexo demais (overfitting). √â tipo "vou te deixar usar esses
                pesos, mas vou cobrar por isso!"<br /><br />

                <strong>Fun√ß√£o de perda COM regulariza√ß√£o:</strong><br />
                Loss_total = Loss_original + Penalidade_dos_pesos<br /><br />

                <strong>Regulariza√ß√£o L1 (Lasso):</strong><br />
                Penalidade = Œª √ó Œ£|w_i|<br />
                (soma dos valores ABSOLUTOS dos pesos)<br /><br />
                <strong>Caracter√≠stica especial de L1:</strong> ZERA pesos!<br /><br />
                Por qu√™? A penalidade |w| tem "quina" em zero. Durante
                otimiza√ß√£o, pesos pequenos s√£o empurrados para exatamente 0.<br /><br />
                <strong>Resultado:</strong><br />
                Modelo final: w = [0.5, 0, 0, 2.1, 0, 0, 1.3, 0]<br />
                Apenas 3 de 8 features s√£o usadas! ‚Üí SPARSIDADE (esparsidade)<br /><br />

                <strong>Regulariza√ß√£o L2 (Ridge):</strong><br />
                Penalidade = Œª √ó Œ£(w_i¬≤)<br />
                (soma dos pesos ao QUADRADO)<br /><br />
                <strong>Caracter√≠stica de L2:</strong> Reduz pesos mas raramente
                zera<br /><br />
                <strong>Resultado:</strong><br />
                Modelo final: w = [0.3, 0.1, 0.05, 1.2, 0.08, 0.02, 0.9,
                0.15]<br />
                Todos os pesos pequenos mas nenhum zero<br /><br />

                <strong>Por que B est√° correta:</strong><br />
                L1 √© √∫til para SELE√á√ÉO DE FEATURES!<br />
                Se voc√™ tem 1000 features mas s√≥ 20 s√£o relevantes, L1
                automaticamente descobre e zera as 980 irrelevantes.<br /><br />

                <strong>Quando usar cada uma:</strong><br /><br />
                <strong>Use L1 quando:</strong><br />
                ‚Ä¢ Voc√™ tem MUITAS features<br />
                ‚Ä¢ Suspeita que muitas s√£o irrelevantes<br />
                ‚Ä¢ Quer um modelo INTERPRETAVEL (poucas features)<br />
                ‚Ä¢ Quer sele√ß√£o autom√°tica de features<br /><br />

                <strong>Use L2 quando:</strong><br />
                ‚Ä¢ Todas as features s√£o potencialmente relevantes<br />
                ‚Ä¢ Quer prevenir pesos muito grandes<br />
                ‚Ä¢ Features s√£o correlacionadas<br />
                ‚Ä¢ Quer modelo mais est√°vel<br /><br />

                <strong>Elastic Net:</strong> Combina L1 + L2!<br />
                Penalidade = Œª‚ÇÅ√óŒ£|w| + Œª‚ÇÇ√óŒ£(w¬≤)<br />
                Pega o melhor dos dois mundos!<br /><br />

                <strong>Exemplo pr√°tico:</strong><br />
                Pre√ßo de casa com 50 features (tamanho, quartos,
                dist√¢ncia_praia, cor_parede, ...)<br /><br />
                L1: Vai zerar features in√∫teis como "cor_parede"<br />
                Resultado: Modelo usa s√≥ 5 features importantes<br /><br />
                L2: Vai manter todas mas com pesos pequenos<br />
                Resultado: Modelo usa todas as 50 features<br /><br />

                <strong>üí° Mnem√¥nico:</strong><br />
                L1 = Less features (menos features, zera)<br />
                L2 = Low weights (pesos baixos, n√£o zera)
              </div>
            </div>
          </div>
        </div>

        <!-- 16 -->
        <div class="question">
          <div class="question-title">16)</div>
          <div class="question-text">
            Em uma rede neural com 3 camadas ocultas usando fun√ß√£o de ativa√ß√£o
            ReLU, o que acontece quando um neur√¥nio tem todos os pesos que levam
            a ele negativos e recebe apenas entradas positivas?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q16" value="A" /> A) O neur√¥nio sempre
              produz sa√≠da positiva</label
            >
            <label
              ><input type="radio" name="q16" value="B" /> B) O neur√¥nio entra
              em "dead ReLU" e sempre produz zero</label
            >
            <label
              ><input type="radio" name="q16" value="C" /> C) O neur√¥nio oscila
              entre valores positivos e negativos</label
            >
            <label
              ><input type="radio" name="q16" value="D" /> D) A rede
              automaticamente ajusta para sigmoid</label
            >
            <label
              ><input type="radio" name="q16" value="E" /> E) O neur√¥nio mant√©m
              sua sa√≠da anterior (mem√≥ria)</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-16"
              onclick="toggleAnswer(16)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-16">
              <div class="correct-answer">
                ‚úì Resposta Correta: B) O neur√¥nio entra em "dead ReLU" e sempre
                produz zero
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© ReLU?</strong><br />
                ReLU (Rectified Linear Unit) √© uma fun√ß√£o de ativa√ß√£o muito
                usada em redes neurais.<br /><br />
                <strong>F√≥rmula:</strong> ReLU(x) = max(0, x)<br />
                ‚Ä¢ Se x > 0 ‚Üí retorna x<br />
                ‚Ä¢ Se x ‚â§ 0 ‚Üí retorna 0<br /><br />

                <strong>Cen√°rio da quest√£o:</strong><br />
                ‚Ä¢ Neur√¥nio tem pesos NEGATIVOS: w = [-0.5, -0.3, -0.8]<br />
                ‚Ä¢ Entradas s√£o POSITIVAS: x = [2, 3, 1]<br /><br />

                <strong>C√°lculo passo a passo:</strong><br />
                1. Soma ponderada: z = w¬∑x = (-0.5)√ó2 + (-0.3)√ó3 + (-0.8)√ó1 =
                -1.0 - 0.9 - 0.8 = -2.7<br />
                2. Ativa√ß√£o ReLU: a = ReLU(-2.7) = max(0, -2.7) = 0<br /><br />
                Sa√≠da = 0 sempre!<br /><br />

                <strong>Por que B est√° correta: Dead ReLU Problem</strong
                ><br /><br />
                <strong>O que acontece no treino:</strong><br />
                1. Neur√¥nio produz sa√≠da = 0<br />
                2. Backpropagation calcula gradiente<br />
                3. Derivada de ReLU em x<0 = 0<br />
                4. Gradiente = 0 ‚Üí pesos N√ÉO ATUALIZAM!<br />
                5. Neur√¥nio fica "morto" para sempre üíÄ<br /><br />

                <strong>Analogia:</strong><br />
                √â tipo um estudante que tirou zero na primeira prova e desistiu
                de estudar. Ele nunca vai melhorar porque parou de tentar!<br /><br />

                <strong>Problema na pr√°tica:</strong><br />
                Se muitos neur√¥nios "morrem", a rede perde capacidade. Pode
                perder 20-30% dos neur√¥nios!<br /><br />

                <strong>Causas comuns de Dead ReLU:</strong><br />
                ‚Ä¢ Taxa de aprendizado muito alta<br />
                ‚Ä¢ Inicializa√ß√£o ruim dos pesos<br />
                ‚Ä¢ Gradientes grandes empurram pesos para valores negativos<br /><br />

                <strong>Solu√ß√µes:</strong><br /><br />
                <strong>1. Leaky ReLU:</strong><br />
                LeakyReLU(x) = max(0.01x, x)<br />
                Em vez de zero, retorna 0.01x quando negativo<br />
                Gradiente pequeno mas existe! Neur√¥nio pode "reviver"<br /><br />

                <strong>2. Parametric ReLU (PReLU):</strong><br />
                PReLU(x) = max(Œ±x, x)<br />
                Onde Œ± √© aprendido durante o treino<br /><br />

                <strong>3. ELU (Exponential Linear Unit):</strong><br />
                ELU(x) = x se x>0, sen√£o Œ±(e^x - 1)<br /><br />

                <strong>4. Inicializa√ß√£o He:</strong><br />
                Inicializar pesos corretamente (He initialization)<br />
                Reduz chance de neur√¥nios come√ßarem "mortos"<br /><br />

                <strong>5. Usar Batch Normalization:</strong><br />
                Normaliza entradas, reduz valores extremos<br /><br />

                <strong>Por que as outras est√£o erradas:</strong><br />
                ‚Ä¢ A) Sa√≠da √© sempre ZERO (n√£o positiva)<br />
                ‚Ä¢ C) N√£o oscila, fica travado em zero<br />
                ‚Ä¢ D) N√£o muda automaticamente para sigmoid<br />
                ‚Ä¢ E) ReLU n√£o tem mem√≥ria (isso seria LSTM/GRU)<br /><br />

                <strong>üí° Resumo:</strong> Dead ReLU = neur√¥nio em coma que
                nunca acorda. Use Leaky ReLU para dar "sinal vital"!
              </div>
            </div>
          </div>
        </div>

        <!-- 17 -->
        <div class="question">
          <div class="question-title">17)</div>
          <div class="question-text">
            No algoritmo Expectation-Maximization (EM) para Gaussian Mixture
            Models (GMM), qual √© a fun√ß√£o do passo E (Expectation)?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q17" value="A" /> A) Atualizar os
              par√¢metros das gaussianas (m√©dia e covari√¢ncia)</label
            >
            <label
              ><input type="radio" name="q17" value="B" /> B) Calcular a
              probabilidade posterior de cada ponto pertencer a cada
              cluster</label
            >
            <label
              ><input type="radio" name="q17" value="C" /> C) Determinar o
              n√∫mero √≥timo de componentes do modelo</label
            >
            <label
              ><input type="radio" name="q17" value="D" /> D) Inicializar
              aleatoriamente os centroides</label
            >
            <label
              ><input type="radio" name="q17" value="E" /> E) Calcular a fun√ß√£o
              de perda final do modelo</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-17"
              onclick="toggleAnswer(17)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-17">
              <div class="correct-answer">
                ‚úì Resposta Correta: B) Calcular a probabilidade posterior de
                cada ponto pertencer a cada cluster
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© GMM (Gaussian Mixture Model)?</strong><br />
                √â um algoritmo de clustering que assume que os dados v√™m de uma
                MISTURA de distribui√ß√µes gaussianas (normais).<br /><br />

                <strong>Diferen√ßa para K-means:</strong><br />
                ‚Ä¢ <strong>K-means:</strong> "Cada ponto pertence a UM cluster"
                (hard assignment)<br />
                ‚Ä¢ <strong>GMM:</strong> "Cada ponto tem PROBABILIDADE de
                pertencer a cada cluster" (soft assignment)<br /><br />

                <strong>Exemplo:</strong><br />
                Ponto X: 70% cluster A, 25% cluster B, 5% cluster C<br /><br />

                <strong>O que √© EM (Expectation-Maximization)?</strong><br />
                √â o algoritmo usado para treinar GMM. Tem 2 passos que se
                alternam:<br /><br />

                <strong>PASSO E (Expectation) ‚úì RESPOSTA CORRETA</strong><br />
                <strong>"Expectativa":</strong> Dado os par√¢metros atuais, qual
                a probabilidade de cada ponto pertencer a cada cluster?<br /><br />
                <strong>C√°lculo:</strong><br />
                Para cada ponto x_i e cada cluster k:<br />
                P(cluster k | x_i) = probabilidade posterior<br /><br />
                Usa Teorema de Bayes:<br />
                P(k|x) = [P(x|k) √ó P(k)] / P(x)<br /><br />
                <strong>Resultado do passo E:</strong><br />
                Matriz de responsabilidades (responsibilities)<br />
                Cada linha = um ponto<br />
                Cada coluna = probabilidade de pertencer a cada cluster<br /><br />
                Exemplo:<br />
                Ponto 1: [0.9, 0.05, 0.05]<br />
                Ponto 2: [0.1, 0.8, 0.1]<br />
                Ponto 3: [0.2, 0.3, 0.5]<br /><br />

                <strong>PASSO M (Maximization)</strong><br />
                <strong>"Maximiza√ß√£o":</strong> Dado as probabilidades, atualize
                os par√¢metros para maximizar a verossimilhan√ßa.<br /><br />
                <strong>Atualiza:</strong><br />
                ‚Ä¢ M√©dias (Œº) de cada gaussiana<br />
                ‚Ä¢ Covari√¢ncias (Œ£) de cada gaussiana<br />
                ‚Ä¢ Pesos (œÄ) de cada componente<br /><br />

                <strong>Algoritmo completo:</strong><br />
                1. <strong>Inicializa√ß√£o:</strong> Escolhe par√¢metros iniciais
                aleat√≥rios<br />
                2. <strong>Passo E:</strong> Calcula probabilidades (resposta
                B)<br />
                3. <strong>Passo M:</strong> Atualiza par√¢metros<br />
                4. Repete 2-3 at√© converg√™ncia<br /><br />

                <strong>Exemplo pr√°tico com 2 clusters:</strong><br /><br />
                <strong>Itera√ß√£o 1:</strong><br />
                Passo E: "Baseado nas gaussianas atuais, ponto X tem 60% chance
                de ser cluster 1"<br />
                Passo M: "Baseado nessas probabilidades, ajuste a m√©dia do
                cluster 1 para 5.2"<br /><br />
                <strong>Itera√ß√£o 2:</strong><br />
                Passo E: "Com novos par√¢metros, ponto X agora tem 75% chance de
                ser cluster 1"<br />
                Passo M: "Ajuste a m√©dia do cluster 1 para 5.5"<br /><br />
                Continua at√© estabilizar...<br /><br />

                <strong>Por que as outras est√£o erradas:</strong><br />
                ‚Ä¢ A) Atualizar par√¢metros √© o passo M (n√£o E)<br />
                ‚Ä¢ C) N√∫mero de componentes √© escolhido ANTES (como K no
                K-means)<br />
                ‚Ä¢ D) Inicializa√ß√£o √© feita ANTES do EM come√ßar<br />
                ‚Ä¢ E) Fun√ß√£o de perda √© calculada mas n√£o √© o objetivo do passo
                E<br /><br />

                <strong>Vantagens do GMM sobre K-means:</strong><br />
                ‚Ä¢ Clusters podem ter formas el√≠pticas (n√£o s√≥ c√≠rculos)<br />
                ‚Ä¢ D√° probabilidades (melhor para incerteza)<br />
                ‚Ä¢ Clusters podem ter tamanhos diferentes<br /><br />

                <strong>üí° Mnem√¥nico:</strong><br />
                <strong>E</strong>xpectation = <strong>E</strong>stimar
                probabilidades<br />
                <strong>M</strong>aximization = <strong>M</strong>udar
                par√¢metros
              </div>
            </div>
          </div>
        </div>

        <!-- 18 -->
        <div class="question">
          <div class="question-title">18)</div>
          <div class="question-text">
            Em valida√ß√£o cruzada k-fold, considere k = 5 e um dataset com 1000
            exemplos. Em cada itera√ß√£o, quantos exemplos s√£o usados para
            treinamento e quantos para valida√ß√£o, respectivamente?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q18" value="A" /> A) 500 para
              treinamento, 500 para valida√ß√£o</label
            >
            <label
              ><input type="radio" name="q18" value="B" /> B) 900 para
              treinamento, 100 para valida√ß√£o</label
            >
            <label
              ><input type="radio" name="q18" value="C" /> C) 800 para
              treinamento, 200 para valida√ß√£o</label
            >
            <label
              ><input type="radio" name="q18" value="D" /> D) 750 para
              treinamento, 250 para valida√ß√£o</label
            >
            <label
              ><input type="radio" name="q18" value="E" /> E) 1000 para
              treinamento, 200 para valida√ß√£o</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-18"
              onclick="toggleAnswer(18)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-18">
              <div class="correct-answer">
                ‚úì Resposta Correta: C) 800 para treinamento, 200 para valida√ß√£o
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong>üìö O que √© Valida√ß√£o Cruzada (Cross-Validation)?</strong
                ><br />
                √â uma t√©cnica para avaliar modelos de forma mais confi√°vel,
                usando diferentes subconjuntos dos dados para treino e
                valida√ß√£o.<br /><br />

                <strong>Por que usar?</strong><br />
                ‚Ä¢ Uma √∫nica divis√£o treino/teste pode dar sorte ou azar<br />
                ‚Ä¢ Cross-validation d√° resultado mais confi√°vel<br />
                ‚Ä¢ Usa todos os dados tanto para treino quanto valida√ß√£o<br /><br />

                <strong>K-Fold Cross-Validation:</strong><br />
                Divide os dados em K partes (folds) iguais<br /><br />

                <strong>C√°lculo para k=5 e 1000 exemplos:</strong><br /><br />
                1. Divide 1000 exemplos em 5 partes: 1000 √∑ 5 = 200 exemplos por
                parte<br /><br />
                2. Em cada itera√ß√£o:<br />
                ‚Ä¢ 1 parte para VALIDA√á√ÉO = 200 exemplos<br />
                ‚Ä¢ 4 partes para TREINAMENTO = 4 √ó 200 = 800 exemplos<br /><br />
                <strong
                  >Por que C est√° correta: 800 treino, 200 valida√ß√£o ‚úì</strong
                ><br /><br />

                <strong>Visualiza√ß√£o do processo completo:</strong><br /><br />
                Dataset: [Part1][Part2][Part3][Part4][Part5]<br />
                Cada parte tem 200 exemplos<br /><br />
                <strong>Itera√ß√£o 1:</strong><br />
                Valida√ß√£o: [Part1]<br />
                Treinamento: [Part2][Part3][Part4][Part5]<br />
                ‚Üí Treina modelo, avalia em Part1, guarda resultado<br /><br />
                <strong>Itera√ß√£o 2:</strong><br />
                Valida√ß√£o: [Part2]<br />
                Treinamento: [Part1][Part3][Part4][Part5]<br />
                ‚Üí Treina novo modelo, avalia em Part2<br /><br />
                <strong>Itera√ß√£o 3:</strong><br />
                Valida√ß√£o: [Part3]<br />
                Treinamento: [Part1][Part2][Part4][Part5]<br /><br />
                <strong>Itera√ß√£o 4:</strong><br />
                Valida√ß√£o: [Part4]<br />
                Treinamento: [Part1][Part2][Part3][Part5]<br /><br />
                <strong>Itera√ß√£o 5:</strong><br />
                Valida√ß√£o: [Part5]<br />
                Treinamento: [Part1][Part2][Part3][Part4]<br /><br />
                <strong>Resultado final:</strong> M√©dia dos 5 resultados!<br /><br />

                <strong>F√≥rmula geral:</strong><br />
                ‚Ä¢ Tamanho de cada fold = N / k<br />
                ‚Ä¢ Valida√ß√£o por itera√ß√£o = N / k<br />
                ‚Ä¢ Treinamento por itera√ß√£o = N - (N/k) = N √ó (k-1)/k<br /><br />
                Para k=5, N=1000:<br />
                ‚Ä¢ Valida√ß√£o = 1000/5 = 200 ‚úì<br />
                ‚Ä¢ Treinamento = 1000 √ó 4/5 = 800 ‚úì<br /><br />

                <strong>Valores comuns de k:</strong><br />
                ‚Ä¢ <strong>k=5:</strong> R√°pido, boa estimativa (80% treino, 20%
                valida√ß√£o)<br />
                ‚Ä¢ <strong>k=10:</strong> Mais comum, bom balan√ßo (90% treino,
                10% valida√ß√£o)<br />
                ‚Ä¢ <strong>k=N (LOOCV):</strong> Leave-One-Out, usa N-1 para
                treino, 1 para valida√ß√£o. Muito lento mas preciso<br /><br />

                <strong>Vantagens:</strong><br />
                ‚Ä¢ Todos os dados s√£o usados para valida√ß√£o<br />
                ‚Ä¢ Reduz vari√¢ncia da estimativa<br />
                ‚Ä¢ Melhor uso de dados limitados<br /><br />

                <strong>Desvantagens:</strong><br />
                ‚Ä¢ k vezes mais lento (treina k modelos)<br />
                ‚Ä¢ N√£o adequado para datasets MUITO grandes<br /><br />

                <strong>Quando usar:</strong><br />
                ‚Ä¢ Dataset pequeno/m√©dio<br />
                ‚Ä¢ Quando precisa de estimativa confi√°vel<br />
                ‚Ä¢ Escolha de hiperpar√¢metros<br />
                ‚Ä¢ Compara√ß√£o de modelos<br /><br />

                <strong>üí° Lembrete:</strong> Em k-fold, usa (k-1)/k para treino
                e 1/k para valida√ß√£o!
              </div>
            </div>
          </div>
        </div>

        <!-- 19 -->
        <div class="question">
          <div class="question-title">19)</div>
          <div class="question-text">
            No contexto de Redes Adversariais Generativas (GANs), qual √© o
            objetivo do discriminador durante o treinamento?
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q19" value="A" /> A) Gerar novas
              amostras sint√©ticas realistas</label
            >
            <label
              ><input type="radio" name="q19" value="B" /> B) Distinguir entre
              amostras reais e amostras geradas pelo gerador</label
            >
            <label
              ><input type="radio" name="q19" value="C" /> C) Comprimir as
              dimens√µes dos dados de entrada</label
            >
            <label
              ><input type="radio" name="q19" value="D" /> D) Classificar as
              imagens em m√∫ltiplas categorias</label
            >
            <label
              ><input type="radio" name="q19" value="E" /> E) Otimizar apenas a
              fun√ß√£o de perda do gerador</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-19"
              onclick="toggleAnswer(19)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-19">
              <div class="correct-answer">
                ‚úì Resposta Correta: B) Distinguir entre amostras reais e
                amostras geradas pelo gerador
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong
                  >üìö O que s√£o GANs (Generative Adversarial Networks)?</strong
                ><br />
                S√£o duas redes neurais que "competem" uma contra a outra para
                gerar dados realistas (imagens, √°udio, texto).<br /><br />

                <strong>Analogia simples:</strong><br />
                ‚Ä¢ <strong>Gerador:</strong> Falsificador tentando criar dinheiro
                falso<br />
                ‚Ä¢ <strong>Discriminador:</strong> Policial tentando detectar o
                dinheiro falso<br /><br />
                Conforme o falsificador melhora, o policial tamb√©m precisa
                melhorar. No final, o dinheiro falso fica perfeito!<br /><br />

                <strong>As duas redes:</strong><br /><br />
                <strong>1. GERADOR (G):</strong><br />
                <strong>Entrada:</strong> Ru√≠do aleat√≥rio (vetor de n√∫meros
                aleat√≥rios)<br />
                <strong>Sa√≠da:</strong> Imagem/dado sint√©tico<br />
                <strong>Objetivo:</strong> Enganar o discriminador<br /><br />
                Exemplo: [0.5, 0.2, 0.9, ...] (ru√≠do) ‚Üí Imagem de gato falso<br /><br />

                <strong>2. DISCRIMINADOR (D) ‚úì RESPOSTA</strong><br />
                <strong>Entrada:</strong> Imagem (real OU gerada)<br />
                <strong>Sa√≠da:</strong> Probabilidade de ser REAL (0 a 1)<br />
                <strong>Objetivo:</strong> Classificar corretamente<br /><br />
                Exemplo:<br />
                ‚Ä¢ Imagem real ‚Üí sa√≠da = 0.95 (95% chance de real) ‚úì<br />
                ‚Ä¢ Imagem falsa ‚Üí sa√≠da = 0.05 (5% chance de real) ‚úì<br /><br />

                <strong>Por que B est√° correta:</strong><br />
                O discriminador √© um CLASSIFICADOR BIN√ÅRIO:<br />
                ‚Ä¢ Classe 0: Imagem falsa (do gerador)<br />
                ‚Ä¢ Classe 1: Imagem real (do dataset)<br /><br />
                Sua tarefa √© DISTINGUIR/DIFERENCIAR as duas!<br /><br />

                <strong>Processo de treinamento (jogo adversarial):</strong
                ><br /><br />
                <strong>Rodada 1:</strong><br />
                1. Gerador cria imagens ruins (in√≠cio do treino)<br />
                2. Discriminador facilmente identifica as falsas<br />
                3. Discriminador: "Essas s√£o obviamente falsas!" (sa√≠da =
                0.01)<br /><br />
                <strong>Rodada 100:</strong><br />
                1. Gerador melhorou, cria imagens melhores<br />
                2. Discriminador precisa ser mais esperto<br />
                3. Discriminador: "Hmm, essa parece 60% real" (sa√≠da = 0.6)<br /><br />
                <strong>Rodada 10000:</strong><br />
                1. Gerador cria imagens quase perfeitas<br />
                2. Discriminador em d√∫vida<br />
                3. Discriminador: "N√£o sei, 50/50" (sa√≠da = 0.5)<br /><br />

                <strong>Equil√≠brio de Nash (objetivo final):</strong><br />
                Quando o discriminador n√£o consegue mais distinguir (sempre d√°
                50%), o gerador venceu!<br /><br />

                <strong>Fun√ß√µes de perda:</strong><br /><br />
                <strong>Discriminador quer MAXIMIZAR:</strong><br />
                L_D = log(D(x_real)) + log(1 - D(G(z)))<br />
                "Quero dar valor alto pra reais e baixo pra falsas"<br /><br />
                <strong>Gerador quer MINIMIZAR:</strong><br />
                L_G = log(1 - D(G(z)))<br />
                "Quero que o discriminador d√™ valor alto pras minhas falsas"<br /><br />

                <strong>Aplica√ß√µes de GANs:</strong><br />
                ‚Ä¢ Gerar rostos realistas (This Person Does Not Exist)<br />
                ‚Ä¢ Criar arte (DALL-E tipo precursor)<br />
                ‚Ä¢ Aumentar resolu√ß√£o de imagens (super-resolution)<br />
                ‚Ä¢ Transferir estilo de imagens<br />
                ‚Ä¢ Gerar vozes sint√©ticas<br />
                ‚Ä¢ Criar personagens de jogos<br /><br />

                <strong>Desafios no treino:</strong><br />
                ‚Ä¢ Mode collapse (gerador s√≥ cria 1 tipo de imagem)<br />
                ‚Ä¢ Instabilidade (um lado domina demais)<br />
                ‚Ä¢ Dif√≠cil de convergir<br />
                ‚Ä¢ Precisa balancear o treino das duas redes<br /><br />

                <strong>Por que as outras est√£o erradas:</strong><br />
                ‚Ä¢ A) GERAR amostras √© trabalho do GERADOR<br />
                ‚Ä¢ C) Comprimir dimens√µes seria autoencoder<br />
                ‚Ä¢ D) Classificar em categorias seria CNN normal<br />
                ‚Ä¢ E) N√£o otimiza s√≥ loss do gerador (tem seu pr√≥prio loss)<br /><br />

                <strong>üí° Resumo:</strong><br />
                Discriminador = Detetive que diz "real ou falso?"<br />
                Gerador = Artista que tenta enganar o detetive
              </div>
            </div>
          </div>
        </div>

        <!-- 20 -->
        <div class="question">
          <div class="question-title">20)</div>
          <div class="question-text">
            Em aprendizado por refor√ßo, a diferen√ßa fundamental entre explora√ß√£o
            (exploration) e explora√ß√£o (exploitation) √©:
          </div>
          <div class="options">
            <label
              ><input type="radio" name="q20" value="A" /> A) Exploration busca
              maximizar recompensas imediatas; exploitation testa novas
              a√ß√µes</label
            >
            <label
              ><input type="radio" name="q20" value="B" /> B) Exploration testa
              a√ß√µes desconhecidas; exploitation escolhe as melhores a√ß√µes
              conhecidas</label
            >
            <label
              ><input type="radio" name="q20" value="C" /> C) Exploration √©
              usada apenas no in√≠cio; exploitation apenas no final</label
            >
            <label
              ><input type="radio" name="q20" value="D" /> D) Ambos os conceitos
              s√£o id√™nticos em valor esperado</label
            >
            <label
              ><input type="radio" name="q20" value="E" /> E) Exploration requer
              mais mem√≥ria que exploitation</label
            >
          </div>
          <div class="answer-section">
            <button
              type="button"
              class="show-answer-btn"
              id="btn-20"
              onclick="toggleAnswer(20)"
            >
              üëÅÔ∏è Mostrar Resposta
            </button>
            <div class="answer-content" id="answer-20">
              <div class="correct-answer">
                ‚úì Resposta Correta: B) Exploration testa a√ß√µes desconhecidas;
                exploitation escolhe as melhores a√ß√µes conhecidas
              </div>
              <div class="explanation">
                <strong>Explica√ß√£o Detalhada:</strong><br /><br />
                <strong
                  >üìö O que √© Aprendizado por Refor√ßo (Reinforcement
                  Learning)?</strong
                ><br />
                Um agente aprende a tomar decis√µes interagindo com um ambiente,
                recebendo recompensas ou puni√ß√µes.<br /><br />
                <strong>Exemplos:</strong><br />
                ‚Ä¢ Rob√¥ aprendendo a andar (recompensa = dist√¢ncia percorrida)<br />
                ‚Ä¢ Jogador de xadrez (recompensa = vit√≥ria)<br />
                ‚Ä¢ Sistema de recomenda√ß√£o (recompensa = usu√°rio clica)<br /><br />

                <strong>O DILEMA: Exploration vs Exploitation</strong><br />
                √â o problema fundamental do aprendizado por refor√ßo!<br /><br />

                <strong>EXPLORATION (Explora√ß√£o):</strong><br />
                <strong>Defini√ß√£o:</strong> Tentar a√ß√µes NOVAS/DESCONHECIDAS
                para descobrir suas recompensas<br /><br />
                <strong>Analogia:</strong> Experimentar restaurantes novos<br />
                ‚Ä¢ "Nunca fui nessa pizzaria, vou testar!"<br />
                ‚Ä¢ Pode ser ruim (perda de tempo)<br />
                ‚Ä¢ Pode ser √ìTIMO (descobriu o melhor lugar!)<br /><br />
                <strong>No RL:</strong> Escolher a√ß√£o aleat√≥ria ou menos
                testada<br /><br />

                <strong>EXPLOITATION (Explota√ß√£o):</strong><br />
                <strong>Defini√ß√£o:</strong> Usar o conhecimento atual para
                maximizar recompensa<br /><br />
                <strong>Analogia:</strong> Ir no restaurante favorito<br />
                ‚Ä¢ "J√° sei que aquela pizzaria √© boa, vou l√°!"<br />
                ‚Ä¢ Garantia de satisfa√ß√£o<br />
                ‚Ä¢ Mas pode estar perdendo algo MELHOR<br /><br />
                <strong>No RL:</strong> Escolher a melhor a√ß√£o segundo Q-values
                atuais<br /><br />

                <strong>Por que B est√° correta:</strong><br />
                Resume perfeitamente a diferen√ßa:<br />
                ‚Ä¢ Exploration = Descobrir o desconhecido<br />
                ‚Ä¢ Exploitation = Aproveitar o conhecido<br /><br />

                <strong>O PROBLEMA do puro Exploitation:</strong><br />
                Imagina que voc√™ testou 3 restaurantes:<br />
                ‚Ä¢ Restaurante A: 7/10<br />
                ‚Ä¢ Restaurante B: 5/10<br />
                ‚Ä¢ Restaurante C: 6/10<br /><br />
                Se s√≥ fazer exploitation, sempre vai no A (7/10).<br />
                MAS existe um restaurante D (ainda n√£o testado) que √© 10/10!<br />
                Voc√™ nunca vai descobrir se n√£o explorar!<br /><br />

                <strong>O PROBLEMA do puro Exploration:</strong><br />
                Fica testando restaurantes aleat√≥rios pra sempre.<br />
                Perde tempo com lugares ruins.<br />
                Nunca aproveita o conhecimento que j√° tem!<br /><br />

                <strong>A SOLU√á√ÉO: Balancear ambos!</strong><br /><br />

                <strong>Estrat√©gias comuns:</strong><br /><br />
                <strong>1. Œµ-greedy (epsilon-greedy):</strong><br />
                ‚Ä¢ Com probabilidade Œµ (ex: 10%): EXPLORE (a√ß√£o aleat√≥ria)<br />
                ‚Ä¢ Com probabilidade 1-Œµ (ex: 90%): EXPLOIT (melhor a√ß√£o
                conhecida)<br /><br />
                Exemplo: 90% das vezes vai no melhor restaurante, 10% testa algo
                novo<br /><br />
                <strong>2. Œµ-greedy decrescente:</strong><br />
                ‚Ä¢ In√≠cio: Œµ = 1.0 (100% exploration)<br />
                ‚Ä¢ Durante treino: Œµ diminui gradualmente<br />
                ‚Ä¢ Final: Œµ = 0.01 (1% exploration)<br /><br />
                L√≥gica: No in√≠cio, explore muito. Depois de aprender, explore
                pouco.<br /><br />
                <strong>3. Softmax / Boltzmann:</strong><br />
                Escolhe a√ß√µes proporcionalmente aos Q-values<br />
                A√ß√µes boas = maior chance, mas outras ainda poss√≠veis<br /><br />
                <strong>4. UCB (Upper Confidence Bound):</strong><br />
                D√° prefer√™ncia para a√ß√µes promissoras E pouco testadas<br />
                "Otimismo diante da incerteza"<br /><br />

                <strong>Exemplo pr√°tico (Pac-Man):</strong><br /><br />
                <strong>Exploration:</strong><br />
                "Vou testar esse corredor novo que nunca explorei"<br />
                ‚Üí Pode achar atalho ou muitas moedas!<br />
                ‚Üí Ou pode ter fantasma e morrer<br /><br />
                <strong>Exploitation:</strong><br />
                "J√° sei que esse caminho √© seguro e tem moedas"<br />
                ‚Üí Garante pontua√ß√£o<br />
                ‚Üí Mas talvez perca oportunidades melhores<br /><br />

                <strong>Quando explorar mais:</strong><br />
                ‚Ä¢ In√≠cio do treinamento<br />
                ‚Ä¢ Ambiente mudou<br />
                ‚Ä¢ Alto custo de errar √© aceit√°vel<br /><br />

                <strong>Quando exploitar mais:</strong><br />
                ‚Ä¢ Final do treinamento / produ√ß√£o<br />
                ‚Ä¢ Alto custo de errar<br />
                ‚Ä¢ J√° conhece bem o ambiente<br /><br />

                <strong>Por que as outras est√£o erradas:</strong><br />
                ‚Ä¢ A) INVERTEU! Exploration testa novas, exploitation maximiza
                conhecidas<br />
                ‚Ä¢ C) Ambos s√£o necess√°rios durante TODO o treino (com propor√ß√µes
                variando)<br />
                ‚Ä¢ D) S√£o MUITO diferentes em prop√≥sito e resultado<br />
                ‚Ä¢ E) Mem√≥ria n√£o √© o fator diferenciador<br /><br />

                <strong>üí° Regra de ouro:</strong><br />
                Explore para DESCOBRIR oportunidades<br />
                Exploite para APROVEITAR o que j√° sabe
              </div>
            </div>
          </div>
        </div>

        <div class="footer">
          <div class="answers-hint">
            Observa√ß√£o: este formul√°rio √© apenas para marca√ß√£o manual e estudo.
            Nenhum dado √© enviado ou salvo automaticamente.
          </div>
          <button type="button" class="export-button" onclick="exportAnswers()">
            üì• Exportar Respostas para TXT
          </button>
        </div>
      </form>
    </main>

    <script>
      function toggleAnswer(questionNumber) {
        const answerContent = document.getElementById(
          `answer-${questionNumber}`
        );
        const button = document.getElementById(`btn-${questionNumber}`);

        if (answerContent.classList.contains("visible")) {
          answerContent.classList.remove("visible");
          button.textContent = "üëÅÔ∏è Mostrar Resposta";
        } else {
          answerContent.classList.add("visible");
          button.textContent = "üôà Ocultar Resposta";
        }
      }

      function exportAnswers() {
        const form = document.querySelector("form");
        let content =
          "REVIS√ÉO - INTELIG√äNCIA ARTIFICIAL / APRENDIZADO DE M√ÅQUINA\n";
        content += "Data: " + new Date().toLocaleString("pt-BR") + "\n";
        content += "=".repeat(70) + "\n\n";

        // Coletar todas as respostas
        for (let i = 1; i <= 20; i++) {
          const selected = form.querySelector(`input[name="q${i}"]:checked`);
          const questionText = document
            .querySelectorAll(".question")
            [i - 1].querySelector(".question-text")
            .textContent.trim();

          content += `Quest√£o ${i}:\n`;
          content +=
            questionText
              .split("\n")
              .map((line) => line.trim())
              .filter((line) => line)
              .join(" ") + "\n";

          if (selected) {
            const selectedLabel = selected.parentElement.textContent.trim();
            content += `Resposta: ${selectedLabel}\n`;
          } else {
            content += "Resposta: [N√ÉO RESPONDIDA]\n";
          }
          content += "\n" + "-".repeat(70) + "\n\n";
        }

        // Criar o arquivo e fazer download
        const blob = new Blob([content], { type: "text/plain;charset=utf-8" });
        const link = document.createElement("a");
        link.href = URL.createObjectURL(blob);
        link.download = "revisao-ia-ml-respostas.txt";
        link.click();
        URL.revokeObjectURL(link.href);
      }
    </script>
  </body>
</html>
